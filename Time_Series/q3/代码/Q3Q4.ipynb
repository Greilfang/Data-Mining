{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据挖掘Q3Q4\n",
    "> 1651718 方沛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import torch\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "import copy\n",
    "import torch.utils.data as da\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对数据集进行预处理,回复时间字符串格式为datetime,同时将pluno类型转化为字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "def read_dataset(path):\n",
    "    dataset = pd.read_csv(path)\n",
    "    dataset['purchase_date']=[x.replace('/','-') for x in dataset[\"purchase_date\"]]\n",
    "    dataset['purchase_date']=pd.to_datetime(dataset['purchase_date'])\n",
    "    dataset['purchase_date']=[datetime.datetime.strftime(x,'%Y-%m-%d') for x in dataset['purchase_date']]\n",
    "    dataset['pluno'] = dataset['pluno'].astype('str')\n",
    "    \n",
    "    plunos = np.unique(dataset['pluno'])\n",
    "    dates = np.unique(dataset['purchase_date'])\n",
    "    train_dates = dates\n",
    "    test_dates = dates[146:]\n",
    "    \n",
    "    for i in range(1,5):\n",
    "        # 训练一个pca\n",
    "        col = \"pl_\"+str(i)\n",
    "        record = dict(dataset.loc[dataset[\"purchase_date\"].isin(train_dates)].groupby(by=[col])['qty'].mean())\n",
    "        dataset[col]=[round(record[x],2) for x in dataset[col]]\n",
    "        \n",
    "        # one-hot\n",
    "        enc=OneHotEncoder(categories='auto')\n",
    "        enc.fit(np.array(dataset[col]).reshape(-1,1))\n",
    "        dplunos = enc.transform(np.array(dataset[col]).reshape(-1,1)).toarray()\n",
    "\n",
    "        # pca\n",
    "        pca=PCA(n_components=1)\n",
    "        pca.fit(dplunos)\n",
    "        compressed_dplunos = pca.transform(dplunos)\n",
    "        compressed_dplunos = np.around(compressed_dplunos, decimals=2)\n",
    "        \n",
    "        dataset[col] =compressed_dplunos[:,0]\n",
    "        for c in range(1,compressed_dplunos.shape[1]):\n",
    "            new_pl = col+'_'+str(c)\n",
    "            col_name = dataset.columns.tolist()\n",
    "            col_name.insert(col_name.index(col)+1,new_pl)\n",
    "            dataset=dataset.reindex(columns=col_name)\n",
    "            dataset[new_pl] = compressed_dplunos[:,c]\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "    return dataset.fillna(0)\n",
    "\n",
    "dataset = read_dataset(\"time_sery.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pluno</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>bndno</th>\n",
       "      <th>pl_1</th>\n",
       "      <th>pl_2</th>\n",
       "      <th>pl_3</th>\n",
       "      <th>pl_4</th>\n",
       "      <th>is_workday</th>\n",
       "      <th>qty</th>\n",
       "      <th>prev_d1</th>\n",
       "      <th>...</th>\n",
       "      <th>pl3_4week_min</th>\n",
       "      <th>pl4_2week_avg</th>\n",
       "      <th>pl4_2week_max</th>\n",
       "      <th>pl4_2week_min</th>\n",
       "      <th>pl4_3week_avg</th>\n",
       "      <th>pl4_3week_max</th>\n",
       "      <th>pl4_3week_min</th>\n",
       "      <th>pl4_4week_avg</th>\n",
       "      <th>pl4_4week_max</th>\n",
       "      <th>pl4_4week_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22000005</td>\n",
       "      <td>2016-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027893</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023714</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22000008</td>\n",
       "      <td>2016-02-18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22000009</td>\n",
       "      <td>2016-07-25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023714</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056571</td>\n",
       "      <td>1.338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22000009</td>\n",
       "      <td>2016-07-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023893</td>\n",
       "      <td>1.338</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22000010</td>\n",
       "      <td>2016-03-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036179</td>\n",
       "      <td>2.026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pluno purchase_date  bndno  pl_1  pl_2  pl_3  pl_4  is_workday    qty  \\\n",
       "0  22000005    2016-07-31      0  0.06  0.06  0.06  0.04           0  0.704   \n",
       "1  22000008    2016-02-18      0  0.06  0.06  0.06  0.04           1  0.704   \n",
       "2  22000009    2016-07-25      0  0.06  0.06  0.06  0.04           1  0.666   \n",
       "3  22000009    2016-07-27      0  0.06  0.06  0.06  0.04           1  1.120   \n",
       "4  22000010    2016-03-16      0  0.06  0.06  0.06  0.04           1  1.914   \n",
       "\n",
       "   prev_d1  ...  pl3_4week_min  pl4_2week_avg  pl4_2week_max  pl4_2week_min  \\\n",
       "0      0.0  ...            0.0       0.027893          1.070            0.0   \n",
       "1      0.0  ...            0.0       0.000000          0.000            0.0   \n",
       "2      0.0  ...            0.0       0.023714          0.728            0.0   \n",
       "3      0.0  ...            0.0       0.032500          0.728            0.0   \n",
       "4      0.0  ...            0.0       0.036179          2.026            0.0   \n",
       "\n",
       "   pl4_3week_avg  pl4_3week_max  pl4_3week_min  pl4_4week_avg  pl4_4week_max  \\\n",
       "0       0.023714          0.728            0.0       0.000000          0.000   \n",
       "1       0.000000          0.000            0.0       0.000000          0.000   \n",
       "2       0.000000          0.000            0.0       0.056571          1.338   \n",
       "3       0.000000          0.000            0.0       0.023893          1.338   \n",
       "4       0.000000          0.000            0.0       0.012571          0.704   \n",
       "\n",
       "   pl4_4week_min  \n",
       "0            0.0  \n",
       "1            0.0  \n",
       "2            0.0  \n",
       "3            0.0  \n",
       "4            0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获得日期和商品订单的序号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plunos = np.unique(dataset['pluno'])\n",
    "dates = np.unique(dataset['purchase_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分需要训练的数据和需要测试的数据,数据在Q2完成保存前被排过序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分需要训练的数据和需要测试的数据,数据已经被预先排过序\n",
    "train_dates = dates[:146]\n",
    "test_dates = dates[146:]\n",
    "# 用训练日期和测试日期获得对应的训练集和测试集\n",
    "trainset=dataset[dataset['purchase_date'].isin(train_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "testset=dataset[dataset['purchase_date'].isin(test_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将pluno离散化化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "precord = dict(dataset.loc[dataset[\"purchase_date\"].isin(train_dates)].groupby(by=['pluno'])['qty'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看训练集和测试集的起始日期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.000e+00, 1.000e-02, 2.000e-02, 3.000e-02, 4.000e-02, 5.000e-02,\n",
       "       6.000e-02, 7.000e-02, 8.000e-02, 9.000e-02, 1.000e-01, 1.600e-01,\n",
       "       1.700e-01, 1.800e-01, 1.900e-01, 2.400e-01, 2.500e-01, 4.000e-01,\n",
       "       4.500e-01, 4.600e-01, 6.600e-01, 7.800e-01, 9.000e-01, 1.090e+00,\n",
       "       2.140e+00, 2.360e+00, 9.190e+00, 6.136e+01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(trainset['pl_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pluno</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>bndno</th>\n",
       "      <th>pl_1</th>\n",
       "      <th>pl_2</th>\n",
       "      <th>pl_3</th>\n",
       "      <th>pl_4</th>\n",
       "      <th>is_workday</th>\n",
       "      <th>qty</th>\n",
       "      <th>prev_d1</th>\n",
       "      <th>...</th>\n",
       "      <th>pl3_4week_min</th>\n",
       "      <th>pl4_2week_avg</th>\n",
       "      <th>pl4_2week_max</th>\n",
       "      <th>pl4_2week_min</th>\n",
       "      <th>pl4_3week_avg</th>\n",
       "      <th>pl4_3week_max</th>\n",
       "      <th>pl4_3week_min</th>\n",
       "      <th>pl4_4week_avg</th>\n",
       "      <th>pl4_4week_max</th>\n",
       "      <th>pl4_4week_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>22000005</td>\n",
       "      <td>2016-06-26</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020286</td>\n",
       "      <td>1.136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042286</td>\n",
       "      <td>1.666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>22000005</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037357</td>\n",
       "      <td>1.136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042286</td>\n",
       "      <td>1.666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>22000005</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062571</td>\n",
       "      <td>1.666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>22000005</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062571</td>\n",
       "      <td>1.666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035679</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>22000005</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062571</td>\n",
       "      <td>1.666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023357</td>\n",
       "      <td>1.308</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pluno purchase_date  bndno  pl_1  pl_2  pl_3  pl_4  is_workday  qty  \\\n",
       "6389  22000005    2016-06-26      0  0.06  0.06  0.06  0.04           0  0.0   \n",
       "6390  22000005    2016-06-27      0  0.06  0.06  0.06  0.04           1  0.0   \n",
       "6391  22000005    2016-06-28      0  0.06  0.06  0.06  0.04           1  0.0   \n",
       "6392  22000005    2016-06-29      0  0.06  0.06  0.06  0.04           1  0.0   \n",
       "6393  22000005    2016-06-30      0  0.06  0.06  0.06  0.04           1  0.0   \n",
       "\n",
       "      prev_d1  ...  pl3_4week_min  pl4_2week_avg  pl4_2week_max  \\\n",
       "6389      0.0  ...            0.0       0.020286          1.136   \n",
       "6390      0.0  ...            0.0       0.037357          1.136   \n",
       "6391      0.0  ...            0.0       0.017071          0.956   \n",
       "6392      0.0  ...            0.0       0.017071          0.956   \n",
       "6393      0.0  ...            0.0       0.017071          0.956   \n",
       "\n",
       "      pl4_2week_min  pl4_3week_avg  pl4_3week_max  pl4_3week_min  \\\n",
       "6389            0.0       0.042286          1.666            0.0   \n",
       "6390            0.0       0.042286          1.666            0.0   \n",
       "6391            0.0       0.062571          1.666            0.0   \n",
       "6392            0.0       0.062571          1.666            0.0   \n",
       "6393            0.0       0.062571          1.666            0.0   \n",
       "\n",
       "      pl4_4week_avg  pl4_4week_max  pl4_4week_min  \n",
       "6389       0.035679          1.308            0.0  \n",
       "6390       0.035679          1.308            0.0  \n",
       "6391       0.035679          1.308            0.0  \n",
       "6392       0.035679          1.308            0.0  \n",
       "6393       0.023357          1.308            0.0  \n",
       "\n",
       "[5 rows x 105 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为训练集只是用来训练模型的,所以不需要保留时序数据,定义一个 $assemble\\_training\\_test$ 将其转化为 $data$ 和 $target$ 的形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_training_set(trainset):\n",
    "    \n",
    "    temp = trainset.drop(['purchase_date', 'bndno'],axis=1)\n",
    "    \n",
    "    temp['pluno']=temp['pluno'].astype(\"int\")\n",
    "    \n",
    "    target = temp['qty']\n",
    "    temp = temp.drop(['qty'],axis = 1)\n",
    "    \n",
    "\n",
    "    temp['pl_1'] = temp['pl_1'].astype(\"float\")\n",
    "    temp['pl_2'] = temp['pl_2'].astype(\"float\")\n",
    "    temp['pl_3'] = temp['pl_3'].astype(\"float\")\n",
    "    temp['pl_4'] = temp['pl_4'].astype(\"float\")\n",
    "        \n",
    "    data = {\n",
    "        'data':temp.values,\n",
    "        'target':target\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用并检查训练数据维度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将测试集重新组织成用于更新时序数据的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_frame(df):\n",
    "    initial_dataset = dict()\n",
    "    temp = df.drop(['purchase_date','bndno'],axis=1)\n",
    "    target = temp['qty']\n",
    "    temp['pl_1'] = temp['pl_1'].astype(\"float\")\n",
    "    temp['pl_2'] = temp['pl_2'].astype(\"float\")\n",
    "    temp['pl_3'] = temp['pl_3'].astype(\"float\")\n",
    "    temp['pl_4'] = temp['pl_4'].astype(\"float\")\n",
    "    for pluno in plunos:\n",
    "        temp_set = temp[temp['pluno']==pluno]\n",
    "        temp_set['pluno']=[precord[x] for x in temp_set['pluno']]\n",
    "        \n",
    "        initial_dataset[pluno]={\n",
    "            'data':temp_set.drop(['qty'],axis=1).values, \n",
    "            'target':temp_set['qty'].values\n",
    "        }\n",
    "    \n",
    "    return initial_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新时序数据的函数,由于有多种场景,这里直接把要更新的特征所在的列号写死"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_time_data(data,loc,pred,qty):\n",
    "    if pred is None or qty is None:\n",
    "        return\n",
    "    elif pred<0:\n",
    "        qty = qty - pred\n",
    "    margin = min(35-loc,7)\n",
    "    for scaner in range(margin):\n",
    "        data[loc+scaner][6+scaner]=data[loc+scaner][6+scaner]+qty\n",
    "    \n",
    "    if data[loc].shape[0]==28:\n",
    "        pass\n",
    "#         data[loc][13] = data[loc][13]+qty/14\n",
    "#         data[loc][16] = data[loc][16]+qty/21\n",
    "#         data[loc][19] = data[loc][16]+qty/28\n",
    "#         data[loc][14] = max(data[loc][14],pred)\n",
    "#         data[loc][17] = max(data[loc][17],pred)\n",
    "#         data[loc][20] = max(data[loc][20],pred)\n",
    "#         data[loc][15] = min(data[loc][15],pred)\n",
    "#         data[loc][18] = min(data[loc][18],pred)\n",
    "#         data[loc][21] = min(data[loc][21],pred)\n",
    "    elif data[loc].shape[0]==57:\n",
    "        margin = min(35-loc,7)\n",
    "        for scaner in range(margin):\n",
    "            data[loc+scaner][13+scaner]=data[loc+scaner][13+scaner]+qty\n",
    "            data[loc+scaner][20+scaner]=data[loc+scaner][20+scaner]+qty\n",
    "            data[loc+scaner][27+scaner]=data[loc+scaner][27+scaner]+qty\n",
    "            data[loc+scaner][34+scaner]=data[loc+scaner][34+scaner]+qty\n",
    "            data[loc+scaner][41+scaner]=data[loc+scaner][41+scaner]+qty\n",
    "        \n",
    "#         data[loc][20] = data[loc][20]+qty/14\n",
    "#         data[loc][23] = data[loc][23]+qty/21\n",
    "#         data[loc][26] = data[loc][26]+qty/28\n",
    "#         data[loc][21] = max(data[loc][21],pred)\n",
    "#         data[loc][24] = max(data[loc][24],pred)\n",
    "#         data[loc][27] = max(data[loc][27],pred)\n",
    "#         data[loc][22] = min(data[loc][22],pred)\n",
    "#         data[loc][25] = min(data[loc][25],pred)\n",
    "#         data[loc][28] = min(data[loc][28],pred)\n",
    "        \n",
    "#         data[loc][29] = data[loc][29]+qty/14\n",
    "#         data[loc][32] = data[loc][32]+qty/21\n",
    "#         data[loc][35] = data[loc][35]+qty/28\n",
    "#         data[loc][30] = max(data[loc][30],pred)\n",
    "#         data[loc][33] = max(data[loc][33],pred)\n",
    "#         data[loc][36] = max(data[loc][36],pred)\n",
    "#         data[loc][31] = min(data[loc][31],pred)\n",
    "#         data[loc][34] = min(data[loc][34],pred)\n",
    "#         data[loc][37] = min(data[loc][37],pred)\n",
    "        \n",
    "    elif data[loc].shape[0]>57:\n",
    "        margin = min(35-loc,7)\n",
    "        for scaner in range(margin):\n",
    "            data[loc+scaner][13+scaner]=data[loc+scaner][13+scaner]+qty\n",
    "            data[loc+scaner][20+scaner]=data[loc+scaner][20+scaner]+qty\n",
    "            data[loc+scaner][27+scaner]=data[loc+scaner][27+scaner]+qty\n",
    "            data[loc+scaner][34+scaner]=data[loc+scaner][34+scaner]+qty\n",
    "            data[loc+scaner][41+scaner]=data[loc+scaner][41+scaner]+qty\n",
    "        \n",
    "#         for i in range(6):\n",
    "#             data[loc][48+i*9] = data[loc][48+i*9]+qty/14\n",
    "#             data[loc][51+i*9] = data[loc][51+i*9]+qty/21\n",
    "#             data[loc][54+i*9] = data[loc][54+i*9]+qty/28\n",
    "#             data[loc][49+i*9] = max(data[loc][49+i*9],pred)\n",
    "#             data[loc][52+i*9] = max(data[loc][52+i*9],pred)\n",
    "#             data[loc][55+i*9] = max(data[loc][55+i*9],pred)\n",
    "#             data[loc][50+i*9] = min(data[loc][50+i*9],pred)\n",
    "#             data[loc][53+i*9] = min(data[loc][53+i*9],pred)\n",
    "#             data[loc][56+i*9] = min(data[loc][56+i*9],pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用于计算每个pluno的 $RSE$, $sample\\_rse$ 在论文中公式中的分子计算时用到, $sample\\_base\\_rse$ 在分母计算时用到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rse(data,target,loc,days,regressor):\n",
    "    sample_rse = 0\n",
    "    prev_pred,prev_qty = None, None\n",
    "    #更新指定天数后得到qty\n",
    "    for day in range(days):\n",
    "        # 更新时序数据\n",
    "        update_time_data(data,loc+day,prev_pred,prev_qty)\n",
    "        \n",
    "        predicted_target=regressor.predict(data[loc+day].reshape((1,-1)))[0]\n",
    "        prev_pred = predicted_target\n",
    "        real_target = target[loc+day]\n",
    "        prev_qty = predicted_target-real_target\n",
    "        #real_target = target[loc+day]\n",
    "        \n",
    "    sample_rse = prev_qty * prev_qty\n",
    "    #print(\"predicted_target:\",prev_pred)\n",
    "    #sample_rse = sample_rse+sample_day_rse\n",
    "    return sample_rse\n",
    "\n",
    "\n",
    "def get_base_rse(test_set,day):\n",
    "    total_pluno_qty = 0\n",
    "    # 遍历每个商品\n",
    "    for pluno in test_set.keys():\n",
    "        total_pluno_qty = total_pluno_qty + sum_pluno_qty(test_set[pluno]['target'],day)\n",
    "    \n",
    "    # 算出分母里的平均\n",
    "    avg_pluno_qty = total_pluno_qty / (len(test_set)*(len(test_dates)-7))\n",
    "    \n",
    "    total_base_rse = 0 \n",
    "    for pluno in test_set.keys():\n",
    "        total_base_rse = total_base_rse+ sum_pluno_qty((test_set[pluno]['target']-avg_pluno_qty)**2,day)\n",
    "    return total_base_rse\n",
    "    \n",
    "def sum_pluno_qty(targets,day):\n",
    "    sum_qty = 0\n",
    "    length = targets.shape[0]\n",
    "    return np.sum(targets[:-7])\n",
    "#     for d in range(day):\n",
    "#         sum_qty = sum_qty + np.sum(targets[day:length-6+day])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "遍历测试集里的每一个pluno,累加最后获得 $RSE$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_rse(test_set,regressor,days):\n",
    "    total_rse,base_rse = 0,0 \n",
    "    for pluno in plunos:\n",
    "        #表示7天\n",
    "        test_data = copy.deepcopy(test_set[pluno]['data'])\n",
    "        test_target = test_set[pluno]['target']\n",
    "        for index in range(test_data.shape[0]-7):\n",
    "            total_rse = total_rse+sample_rse(test_data,test_target,index,days,regressor)\n",
    "    return total_rse\n",
    "    #print(type(regressor).__name__)\n",
    "    #print(\"RSE:\",math.sqrt(total_rse)/math.sqrt(base_rse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树,随机森林和支持向量机用 sklearn 的 api, mlp使用 pytorch 搭一个,可以添加dropout,设定层数,效果较好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 决策树:\n",
    "#tree_regressor = DecisionTreeRegressor()\n",
    "# 随机森林\n",
    "#forest_regressor = RandomForestRegressor(n_estimators=10)\n",
    "# 支持向量机\n",
    "svm_regressor = svm.SVR()\n",
    "# mlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在正式预测前,由于第四题设置了四个场景 (使用不同的特征),因此我们需要将这四个场景的特征线先划分到4个csv文件中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 仅使用 b.i 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greilfang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "dataset = read_dataset(\"time_sery1.csv\")\n",
    "trainset=dataset.loc[dataset['purchase_date'].isin(train_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "testset=dataset.loc[dataset['purchase_date'].isin(test_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "train_data = assemble_training_set(trainset)\n",
    "test_set = assemble_frame(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:0.40805351726129135\n",
      "day 2 end:1.0008101314161308\n",
      "day 3 end:1.9191557751956771\n",
      "day 4 end:4.958939396376208\n",
      "day 5 end:5.190157361767456\n",
      "day 6 end:5.44425663828467\n",
      "day 7 end:5.566552534133916\n",
      "3.498275050633621\n"
     ]
    }
   ],
   "source": [
    "forest_regressor = RandomForestRegressor(n_estimators=50,max_depth=10)\n",
    "forest_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,forest_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    print(\"day {} end:{}\".format(d,result))\n",
    "    step_rses.append(result)\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_rses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_regressor = svm.SVR(C=0.5, kernel='rbf', gamma=\"auto\",max_iter= 3000)\n",
    "svm_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,svm_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    print(\"day {} end:{}\".format(d,result))\n",
    "    step_rses.append(result)\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_rses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:0.8753102253624371\n",
      "day 2 end:1.0080396334491428\n",
      "day 3 end:1.038135666959623\n",
      "day 4 end:1.4633611069002932\n",
      "day 5 end:3.5756613840643765\n",
      "day 6 end:10.014050310027283\n",
      "day 7 end:23.56191727049414\n",
      "5.933782228179614\n"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(10,4),  activation='relu', solver='adam', alpha=0.0001, batch_size=2048,\n",
    "    learning_rate='adaptive', learning_rate_init=0.0001, power_t=0.5, max_iter=200000, shuffle=True,\n",
    "    tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False,beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "mlp_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,mlp_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    print(\"day {} end:{}\".format(d,result))\n",
    "    step_rses.append(result)\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 仅用 b.i 和 b.iv 特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greilfang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "dataset = read_dataset(\"time_sery2.csv\")\n",
    "trainset=dataset[dataset['purchase_date'].isin(train_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "testset=dataset[dataset['purchase_date'].isin(test_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "train_data = assemble_training_set(trainset)\n",
    "test_set = assemble_frame(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:0.3657065660205173\n",
      "day 2 end:1.73878018728672\n",
      "day 3 end:2.51807215533027\n",
      "day 4 end:2.640986799965096\n",
      "day 5 end:3.4072071119471543\n",
      "day 6 end:5.379465147646563\n",
      "day 7 end:6.1403212885468035\n",
      "3.1700770366775894\n"
     ]
    }
   ],
   "source": [
    "# 这只是第七预测,第n天RSE要每一步前n步取平均\n",
    "forest_regressor = RandomForestRegressor(n_estimators=20,max_depth=10)\n",
    "forest_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,forest_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    print(\"day {} end:{}\".format(d,result))\n",
    "    step_rses.append(result)\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greilfang\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:244: ConvergenceWarning: Solver terminated early (max_iter=7000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-38170c9ba028>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpredict_rse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalculate_rse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msvm_regressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_rse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_rse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mstep_rses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-d2147b1304c1>\u001b[0m in \u001b[0;36mcalculate_rse\u001b[1;34m(test_set, regressor, days)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtest_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpluno\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mtotal_rse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_rse\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msample_rse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_rse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#print(type(regressor).__name__)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-665cd3d652d1>\u001b[0m in \u001b[0;36msample_rse\u001b[1;34m(data, target, loc, days, regressor)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mupdate_time_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprev_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprev_qty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mpredicted_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregressor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprev_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredicted_target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mreal_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mday\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m             cache_size=self.cache_size)\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm_regressor = svm.SVR(C=0.5, kernel='rbf', gamma=\"auto\",max_iter= 3000)\n",
    "svm_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,svm_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    step_rses.append(result)\n",
    "    print(\"day {} end:{}\".format(d,np.mean(step_rses)))\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:0.6943634128428352\n",
      "day 2 end:0.7052097775473407\n",
      "day 3 end:0.7462560571712302\n",
      "day 4 end:0.8100420205858041\n",
      "day 5 end:0.8794033106011743\n",
      "day 6 end:0.969654960735058\n",
      "day 7 end:1.104140667681129\n",
      "1.104140667681129\n"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(18,8),  activation='relu', solver='adam', alpha=0.0001, batch_size=2048,\n",
    "    learning_rate='adaptive', learning_rate_init=0.0001, power_t=0.5, max_iter=200000, shuffle=True,\n",
    "    tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False,beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "mlp_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,mlp_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    step_rses.append(result)\n",
    "    print(\"day {} end:{}\".format(d,np.mean(step_rses)))\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 仅适用 b.i + b.iv + b.ii +b.v  特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greilfang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "dataset = read_dataset(\"time_sery3.csv\")\n",
    "trainset=dataset[dataset['purchase_date'].isin(train_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "testset=dataset[dataset['purchase_date'].isin(test_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "train_data = assemble_training_set(trainset)\n",
    "test_set = assemble_frame(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:0.33420506303244557\n",
      "day 2 end:1.6459634217129648\n",
      "day 3 end:2.7472183800059216\n",
      "day 4 end:3.064354979006559\n",
      "day 5 end:4.2352454890483555\n",
      "day 6 end:5.258971080678135\n",
      "day 7 end:6.032580510166506\n",
      "3.3312198462358404\n"
     ]
    }
   ],
   "source": [
    "forest_regressor = RandomForestRegressor(n_estimators=30,max_depth=10)\n",
    "forest_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,forest_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    print(\"day {} end:{}\".format(d,result))\n",
    "    step_rses.append(result)\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_regressor = svm.SVR(C=0.5, kernel='rbf', gamma=\"auto\",max_iter= 3000)\n",
    "svm_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,svm_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    step_rses.append(result)\n",
    "    print(\"day {} end:{}\".format(d,np.mean(step_rses)))\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:0.7557151225540063\n",
      "day 2 end:0.8272161052089024\n",
      "day 3 end:0.9500560536559851\n",
      "day 4 end:1.0877422862111317\n",
      "day 5 end:1.219521475585465\n",
      "day 6 end:1.3495092405738731\n",
      "day 7 end:1.4509932956450324\n",
      "1.4509932956450324\n"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(32,16),  activation='relu', solver='adam', alpha=0.0001, batch_size=2048,\n",
    "    learning_rate='adaptive', learning_rate_init=0.0001, power_t=0.5, max_iter=200000, shuffle=True,\n",
    "    tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False,beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "mlp_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,mlp_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    step_rses.append(result)\n",
    "    print(\"day {} end:{}\".format(d,np.mean(step_rses)))\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 使用全部特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greilfang\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_dates = dates[21:]\n",
    "dataset = read_dataset(\"time_sery4.csv\")\n",
    "trainset=dataset[dataset['purchase_date'].isin(train_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "testset=dataset[dataset['purchase_date'].isin(test_dates)].sort_values(by=['pluno','purchase_date'],ascending=[True,True])\n",
    "train_data = assemble_training_set(trainset)\n",
    "test_set = assemble_frame(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:0.22082948682220793\n",
      "day 2 end:0.6435019340119283\n",
      "day 3 end:1.305742041530783\n",
      "day 4 end:1.723975827999527\n",
      "day 5 end:2.1146697008462256\n",
      "day 6 end:2.487461731852385\n",
      "day 7 end:2.856799972387743\n",
      "2.856799972387743\n"
     ]
    }
   ],
   "source": [
    "forest_regressor = RandomForestRegressor(n_estimators=30,max_depth=10)\n",
    "forest_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,forest_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    step_rses.append(result)\n",
    "    print(\"day {} end:{}\".format(d,np.mean(step_rses)))\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_regressor = svm.SVR(C=0.5, kernel='rbf', gamma=\"auto\",max_iter= 3000)\n",
    "svm_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,svm_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    step_rses.append(result)\n",
    "    print(\"day {} end:{}\".format(d,np.mean(step_rses)))\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Greilfang\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day 1 end:1.2986071736493512\n",
      "day 2 end:1.3125264461807593\n",
      "day 3 end:1.349650520876328\n",
      "day 4 end:1.398295478745645\n",
      "day 5 end:1.4396624848212738\n",
      "day 6 end:1.4882207912565493\n",
      "day 7 end:1.5352600480228646\n",
      "2.302890072034297\n"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLPRegressor(\n",
    "    hidden_layer_sizes=(64,36,16),  activation='relu', solver='adam', alpha=0.0001, batch_size=2048,\n",
    "    learning_rate='adaptive', learning_rate_init=0.0001, power_t=0.5, max_iter=200000, shuffle=True,\n",
    "    tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "    early_stopping=False,beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "mlp_regressor.fit(train_data['data'],train_data['target'])\n",
    "step_rses = list()\n",
    "base_rse = get_base_rse(test_set,7)\n",
    "\n",
    "\n",
    "for d in range(1,7+1):\n",
    "    predict_rse=calculate_rse(test_set,mlp_regressor,d)\n",
    "    result = math.sqrt(predict_rse)/math.sqrt(base_rse)\n",
    "    step_rses.append(result)\n",
    "    print(\"day {} end:{}\".format(d,np.mean(step_rses)))\n",
    "print(np.mean(step_rses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
